{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "Text mining project - Named Entity Recognition and Classification\n",
    "group 4\n",
    "\n",
    "CONLL\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import nltk\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction import DictVectorizer\n",
    "from sklearn import svm\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "The test set does not have any POS tags yet. We are going to do POS tagging first and then train an SVM to classify Named entity's.\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('Warner', 'B-ORG'), ('Brothers', 'I-ORG'), ('New', 'B-ORG'), ('York', 'I-ORG'), ('University', 'I-ORG'), ('Soho', 'B-LOC'), ('Italian', 'B-MISC'), ('Jane', 'B-PER'), ('Austen', 'I-PER'), ('Carl', 'B-PER'), ('Brashear', 'I-PER'), ('Cuba', 'B-PER'), ('Gooding', 'I-PER'), ('Jr.', 'I-PER'), ('African', 'B-MISC'), ('American', 'I-MISC'), ('Navy', 'B-ORG'), ('Chris', 'B-PER'), (\"O'Donnell\", 'I-PER'), ('Amsterdam', 'B-LOC'), ('Blauwbrug', 'B-ORG'), ('Dame', 'B-PER'), ('Maggie', 'I-PER'), ('Smith', 'I-PER'), ('Mr.', 'B-PER'), ('Kruno', 'I-PER'), ('New', 'B-LOC'), ('York', 'I-LOC'), ('Los', 'B-LOC'), ('Angeles', 'I-LOC'), ('English', 'B-MISC')]\n"
     ]
    }
   ],
   "source": [
    "### This is the test set that we will be dealing with. As we see, there is no POS information yet.\n",
    "\n",
    "ner_df = pd.read_table('NER-final-test.tsv')\n",
    "\n",
    "np_ner_set = ner_df['token'].tolist()\n",
    "ner_iob = ner_df['BIO NER tag'].tolist()\n",
    "\n",
    "\n",
    "counter = 0\n",
    "ner_tuples = []\n",
    "for i in ner_iob:\n",
    "    if i != 'O':\n",
    "        ner_tuples.append((np_ner_set[counter], i))\n",
    "    counter += 1\n",
    "\n",
    "print(ner_tuples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     sentence id  token id  token BIO NER tag  POS\n",
      "0              0         0     It           O  PRP\n",
      "1              0         1   took           O  VBD\n",
      "2              0         2  eight           O   CD\n",
      "3              0         3  years           O  NNS\n",
      "4              0         4    for           O   IN\n",
      "..           ...       ...    ...         ...  ...\n",
      "209            9        12    get           O   VB\n",
      "210            9        13   into           O   IN\n",
      "211            9        14   this           O   DT\n",
      "212            9        15    one           O   CD\n",
      "213            9        16      .           O    .\n",
      "\n",
      "[214 rows x 5 columns]\n"
     ]
    }
   ],
   "source": [
    "# adding POS using NLTK\n",
    "\n",
    "pos_tagged = nltk.pos_tag(np_ner_set)\n",
    "\n",
    "pos_list = []\n",
    "type(pos_tagged)\n",
    "\n",
    "for i in pos_tagged:\n",
    "    pos_list.append(i[1])\n",
    "\n",
    "ner_df['POS'] = pos_list\n",
    "print(ner_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "203621\n"
     ]
    }
   ],
   "source": [
    "# Loading training data and transforming it to a usable format\n",
    "\n",
    "from nltk.corpus.reader import ConllCorpusReader\n",
    "### Adapt the path to point to the CONLL2003 folder on your local machine\n",
    "train = ConllCorpusReader('/Users/tomsl/My Drive/AI/Year 3/P4_TextMining/ba-text-mining/ba-text-mining/lab_sessions/lab4/nerc_datasets/CONLL2003', 'train.txt', ['words', 'pos', 'ignore', 'chunk'])\n",
    "training_X = []\n",
    "training_y = []\n",
    "\n",
    "for token, pos, ne_label in train.iob_words():\n",
    "    a_dict = {\n",
    "        'token': token, 'POS': pos\n",
    "    }\n",
    "    training_X.append(a_dict)\n",
    "    training_y.append(ne_label)\n",
    "\n",
    "print(len(training_y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Getting the test data in the same format as the training data.\n",
    "\n",
    "test_df = ner_df.drop(columns={'sentence id', 'token id', 'BIO NER tag'})\n",
    "\n",
    "test_X = test_df.to_dict(orient='records')\n",
    "test_y = ner_df['BIO NER tag'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In the training set, the counter function produces the following distribution: Counter({'O': 169578, 'B-LOC': 7140, 'B-PER': 6600, 'B-ORG': 6321, 'I-PER': 4528, 'I-ORG': 3704, 'B-MISC': 3438, 'I-LOC': 1157, 'I-MISC': 1155})\n",
      "In the test set, the counter function produces the following distribution: Counter({'O': 183, 'I-PER': 8, 'B-PER': 6, 'B-ORG': 4, 'B-LOC': 4, 'I-ORG': 3, 'B-MISC': 3, 'I-LOC': 2, 'I-MISC': 1})\n",
      "[27, 1, 49, 1, 1, 1, 49, 1, 1, 26]\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter \n",
    "\n",
    "\n",
    "print('In the training set, the counter function produces the following distribution: ' + str(Counter(training_y)))\n",
    "print('In the test set, the counter function produces the following distribution: ' + str(Counter(test_y)))\n",
    "\n",
    "\n",
    "class_count_array = list(Counter(training_y).items())\n",
    "max = np.max(list(Counter(training_y).values()))\n",
    "\n",
    "\n",
    "# creating weights to fight class imbalance\n",
    "weights = []\n",
    "\n",
    "for i in training_y:\n",
    "    for j, k in class_count_array:\n",
    "        if i == j:\n",
    "            x = round((1/k)*max)\n",
    "            weights.append(x)\n",
    "\n",
    "print(weights[:10])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(203621, 23683)\n",
      "(214, 23683)\n"
     ]
    }
   ],
   "source": [
    "# Vectorize our data\n",
    "\n",
    "vec = DictVectorizer()\n",
    "\n",
    "whole_set = training_X + test_X\n",
    "\n",
    "\n",
    "the_array = vec.fit_transform(whole_set)\n",
    "\n",
    "training_array = the_array[:203621]\n",
    "test_array = the_array[203621:]\n",
    "\n",
    "print(training_array.shape)\n",
    "print(test_array.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train an SVM on our training data\n",
    "\n",
    "lin_clf = svm.LinearSVC()\n",
    "\n",
    "lin_clf.fit(training_array, training_y)\n",
    "\n",
    "pred = lin_clf.predict(training_array)\n",
    "test_pred = lin_clf.predict(test_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training report: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       B-LOC       0.89      0.92      0.90      7140\n",
      "      B-MISC       0.90      0.88      0.89      3438\n",
      "       B-ORG       0.88      0.86      0.87      6321\n",
      "       B-PER       0.89      0.90      0.90      6600\n",
      "       I-LOC       0.79      0.79      0.79      1157\n",
      "      I-MISC       0.81      0.71      0.75      1155\n",
      "       I-ORG       0.86      0.74      0.79      3704\n",
      "       I-PER       0.85      0.85      0.85      4528\n",
      "           O       1.00      1.00      1.00    169578\n",
      "\n",
      "    accuracy                           0.98    203621\n",
      "   macro avg       0.87      0.85      0.86    203621\n",
      "weighted avg       0.97      0.98      0.97    203621\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\tomsl\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\tomsl\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\tomsl\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "report_training = classification_report(training_y, pred)\n",
    "report_test = classification_report(test_y, test_pred)\n",
    "\n",
    "print(\"Training report: \\n\" + report_training)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\tomsl\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\svm\\_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Train a model with weights\n",
    "\n",
    "lin_clf_weighted = svm.LinearSVC()\n",
    "\n",
    "lin_clf_weighted.fit(training_array, training_y, sample_weight=weights)\n",
    "\n",
    "pred_weighted = lin_clf_weighted.predict(training_array)\n",
    "test_pred_weighted = lin_clf_weighted.predict(test_array)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Weighted training report: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       B-LOC       0.90      0.91      0.91      7140\n",
      "      B-MISC       0.85      0.90      0.87      3438\n",
      "       B-ORG       0.87      0.85      0.86      6321\n",
      "       B-PER       0.91      0.87      0.89      6600\n",
      "       I-LOC       0.62      0.89      0.73      1157\n",
      "      I-MISC       0.37      0.87      0.52      1155\n",
      "       I-ORG       0.32      0.79      0.46      3704\n",
      "       I-PER       0.81      0.88      0.85      4528\n",
      "           O       1.00      0.95      0.98    169578\n",
      "\n",
      "    accuracy                           0.94    203621\n",
      "   macro avg       0.74      0.88      0.79    203621\n",
      "weighted avg       0.96      0.94      0.95    203621\n",
      "\n"
     ]
    }
   ],
   "source": [
    "report_training_weighted = classification_report(training_y, pred_weighted)\n",
    "\n",
    "print(\"Weighted training report: \\n\" + report_training_weighted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test report: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       B-LOC       0.50      0.50      0.50         4\n",
      "      B-MISC       0.67      0.67      0.67         3\n",
      "       B-ORG       0.00      0.00      0.00         4\n",
      "       B-PER       0.75      0.50      0.60         6\n",
      "       I-LOC       0.67      1.00      0.80         2\n",
      "      I-MISC       0.00      0.00      0.00         1\n",
      "       I-ORG       0.50      0.67      0.57         3\n",
      "       I-PER       0.64      0.88      0.74         8\n",
      "           O       0.99      1.00      1.00       183\n",
      "\n",
      "    accuracy                           0.94       214\n",
      "   macro avg       0.52      0.58      0.54       214\n",
      "weighted avg       0.93      0.94      0.93       214\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\tomsl\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\tomsl\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\tomsl\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\tomsl\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\tomsl\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\tomsl\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "report_test = classification_report(test_y, test_pred)\n",
    "report_weighted = classification_report(test_y, test_pred_weighted)\n",
    "\n",
    "print(\"Test report: \\n\" + report_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Weighted test report: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       B-LOC       0.50      0.50      0.50         4\n",
      "      B-MISC       0.67      0.67      0.67         3\n",
      "       B-ORG       0.00      0.00      0.00         4\n",
      "       B-PER       0.75      0.50      0.60         6\n",
      "       I-LOC       0.67      1.00      0.80         2\n",
      "      I-MISC       0.00      0.00      0.00         1\n",
      "       I-ORG       0.29      0.67      0.40         3\n",
      "       I-PER       0.64      0.88      0.74         8\n",
      "           O       0.99      0.97      0.98       183\n",
      "\n",
      "    accuracy                           0.92       214\n",
      "   macro avg       0.50      0.58      0.52       214\n",
      "weighted avg       0.92      0.92      0.92       214\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Weighted test report: \\n\" + report_weighted)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "We can see from the classification reports above that the there is a performance decrease when introducing weights. For every non 'O' class, the prediction scores are outperformed by SVM trained without weights.\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Warner', 'B-ORG')\n",
      "('Warner', 'I-PER')\n",
      "('Brothers', 'I-ORG')\n",
      "('Brothers', 'I-ORG')\n",
      "('New', 'B-ORG')\n",
      "('New', 'B-LOC')\n",
      "('York', 'I-ORG')\n",
      "('York', 'I-LOC')\n",
      "('University', 'I-ORG')\n",
      "('University', 'I-ORG')\n",
      "('Soho', 'B-LOC')\n",
      "('Soho', 'I-PER')\n",
      "('Italian', 'B-MISC')\n",
      "('Italian', 'B-MISC')\n",
      "('Jane', 'B-PER')\n",
      "('Jane', 'B-PER')\n",
      "('Austen', 'I-PER')\n",
      "('Austen', 'I-PER')\n",
      "('Carl', 'B-PER')\n",
      "('Carl', 'B-PER')\n",
      "('Brashear', 'I-PER')\n",
      "('Brashear', 'I-PER')\n",
      "('Cuba', 'B-PER')\n",
      "('Cuba', 'B-LOC')\n",
      "('Gooding', 'I-PER')\n",
      "('Gooding', 'I-PER')\n",
      "('Jr.', 'I-PER')\n",
      "('Jr.', 'I-PER')\n",
      "('African', 'B-MISC')\n",
      "('African', 'I-MISC')\n",
      "('American', 'I-MISC')\n",
      "('American', 'B-MISC')\n",
      "('Navy', 'B-ORG')\n",
      "('Navy', 'I-ORG')\n",
      "('Chris', 'B-PER')\n",
      "('Chris', 'B-PER')\n",
      "(\"O'Donnell\", 'I-PER')\n",
      "(\"O'Donnell\", 'I-PER')\n",
      "('Amsterdam', 'B-LOC')\n",
      "('Amsterdam', 'I-ORG')\n",
      "('Blauwbrug', 'B-ORG')\n",
      "('Blauwbrug', 'I-PER')\n",
      "('Dame', 'B-PER')\n",
      "('Dame', 'I-PER')\n",
      "('Maggie', 'I-PER')\n",
      "('Maggie', 'B-PER')\n",
      "('Smith', 'I-PER')\n",
      "('Smith', 'I-PER')\n",
      "('Mr.', 'B-PER')\n",
      "('Kruno', 'I-PER')\n",
      "('Kruno', 'I-PER')\n",
      "('New', 'B-LOC')\n",
      "('New', 'B-LOC')\n",
      "('York', 'I-LOC')\n",
      "('York', 'I-LOC')\n",
      "('Los', 'B-LOC')\n",
      "('Los', 'B-LOC')\n",
      "('Angeles', 'I-LOC')\n",
      "('Angeles', 'I-LOC')\n",
      "('English', 'B-MISC')\n",
      "Mr.\n",
      "1\n",
      "0.967741935483871\n"
     ]
    }
   ],
   "source": [
    "counter = 0 \n",
    "pred_tuples = []\n",
    "for i in test_pred:\n",
    "    if i != 'O':\n",
    "        pred_tuples.append((np_ner_set[counter], i))\n",
    "    counter += 1\n",
    "\n",
    "\n",
    "for i in range(len(pred_tuples)):\n",
    "    print(ner_tuples[i])\n",
    "    print(pred_tuples[i])\n",
    "\n",
    "pred_tokens = []\n",
    "for i in pred_tuples:\n",
    "    pred_tokens.append(i[0])\n",
    "\n",
    "ner_tokens = []\n",
    "for i in ner_tuples:\n",
    "    ner_tokens.append(i[0])\n",
    "\n",
    "counter = 0\n",
    "number_of_ners = len(ner_tokens)\n",
    "counter_inv = number_of_ners\n",
    "for i in ner_tokens:\n",
    "    if i in pred_tokens:\n",
    "        counter_inv -= 1\n",
    "    else:\n",
    "        print(i)\n",
    "        \n",
    "print(counter_inv)\n",
    "\n",
    "precision = (number_of_ners-counter_inv)/number_of_ners\n",
    "print(\"Precision: \" + str(precision))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
